name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    tags: ["v*"]
  pull_request:
    branches: [main, develop]

env:
  REGISTRY: registry.company.com
  IMAGE_NAME: federated-pipeline

jobs:
  # Code Quality and Testing
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      matrix:
        python-version: [ "3.11"]
        component:
          [aggregation-server, edge-coordinator, sdr-client, mobile-client]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install GNU Radio
        run: |
          sudo apt-get update
          sudo apt-get install -y gnuradio python3-packaging


      - name: Cache virtualenv
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('requirements/*.txt') }}


      - name: Debug requirements file
        run: |
          echo "=== Checking requirements/base.txt content ==="
          cat requirements/base.txt
          echo "=== Checking line 10 specifically ==="
          sed -n '10p' requirements/base.txt | cat -A
          echo "=== End debug ==="
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install \
            -r requirements/base.txt \
            -r requirements/${{ matrix.component }}.txt \
            -r requirements/dev.txt \
            -f https://download.pytorch.org/whl/torch_stable.html


      - name: Set up Python path
        run: |
          echo "PYTHONPATH=${{ github.workspace }}/src" >> $GITHUB_ENV

      - name: Lint with flake8
        run: |
          # Convert component name for source directory (aggregation-server -> aggregation_server)
          COMPONENT_DIR=$(echo "${{ matrix.component }}" | sed 's/-/_/g')
          flake8 src/${COMPONENT_DIR}/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/${COMPONENT_DIR}/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Type check with mypy
        run: |
          # Convert component name for source directory (aggregation-server -> aggregation_server)
          COMPONENT_DIR=$(echo "${{ matrix.component }}" | sed 's/-/_/g')
          mypy src/${COMPONENT_DIR}/ || true  # Allow mypy to fail for now

      - name: Test with pytest
        run: |
          # Convert component name for test file (aggregation-server -> aggregation_server)
          COMPONENT_TEST=$(echo "${{ matrix.component }}" | sed 's/-/_/g')
          pytest tests/unit/test_${COMPONENT_TEST}.py -v --cov=src/$(echo "${{ matrix.component }}" | sed 's/-/_/g') --cov-report=xml --cov-report=term-missing

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: ${{ matrix.component }}
          name: codecov-${{ matrix.component }}

  # Security Scanning
  security:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Bandit security scan
        run: |
          pip install bandit
          bandit -r src/ -f json -o bandit-report.json

      - name: Run Safety check
        run: |
          pip install safety
          safety check --json --output safety-report.json

      - name: Upload security reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # Build and Push Docker Images
  build:
    needs: [test, security]
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      matrix:
        component:
          [
            aggregation-server,
            edge-coordinator,
            sdr-client,
            mobile-client,
            metrics-collector,
          ]
        platform: [linux/amd64, linux/arm64]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.component }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.${{ matrix.component }}
          platforms: ${{ matrix.platform }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          target: production

  # Demo Tests
  demo-test:
    needs: test
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install GNU Radio
        run: |
          sudo apt-get update
          sudo apt-get install -y gnuradio python3-packaging
    

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements/dev.txt -f https://download.pytorch.org/whl/torch_stable.html



      - name: Set up Python path
        run: |
          echo "PYTHONPATH=${{ github.workspace }}/src" >> $GITHUB_ENV
          echo "SDR_MOCK_MODE=true" >> $GITHUB_ENV

      - name: Run demo tests
        run: |
          python demos/run_all_demos.py --timeout 300 --no-summary

      - name: Upload demo results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: demo-results-${{ matrix.python-version }}
          path: demo_output/

  # Integration Tests
  integration-test:
    needs: [build, demo-test]
    runs-on: ubuntu-latest
    timeout-minutes: 60
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: federated_pipeline_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Compose
        run: |
          docker-compose -f docker-compose.test.yml up -d
          sleep 30  # Wait for services to start

      - name: Run integration tests
        run: |
          python -m pytest tests/integration/ -v --tb=short

      - name: Collect logs
        if: failure()
        run: |
          docker-compose -f docker-compose.test.yml logs > integration-test-logs.txt

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-logs
          path: integration-test-logs.txt

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.test.yml down -v

  # Performance Testing
  performance-test:
    needs: build
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up performance test environment
        run: |
          docker-compose -f docker-compose.perf.yml up -d
          sleep 60  # Wait for services to fully start

      - name: Install Locust
        run: |
          pip install locust

      - name: Run performance tests
        run: |
          locust -f benchmarks/aggregation_server_benchmark.py --headless -u 100 -r 10 -t 300s --host http://localhost:8000 --html performance-report.html

      - name: Upload performance report
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: performance-report.html

      - name: Cleanup
        if: always()
        run: |
          docker-compose -f docker-compose.perf.yml down -v

  # Deploy to Staging
  deploy-staging:
    needs: [integration-test]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/k8s-set-context@v3
        with:
          method: kubeconfig
          kubeconfig: ${{ secrets.KUBE_CONFIG_STAGING }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.0"

      - name: Deploy to staging
        run: |
          helm upgrade --install federated-pipeline-staging ./helm/federated-pipeline \
            --namespace federated-pipeline-staging \
            --create-namespace \
            --values ./helm/federated-pipeline/values-staging.yaml \
            --set image.tag=${{ github.sha }} \
            --wait --timeout=600s

      - name: Run smoke tests
        run: |
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aggregation-server -n federated-pipeline-staging --timeout=300s
          curl -f http://staging.federated-pipeline.company.com/health

  # Deploy to Production
  deploy-production:
    needs: [performance-test, deploy-staging]
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/k8s-set-context@v3
        with:
          method: kubeconfig
          kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "3.12.0"

      - name: Deploy to production
        run: |
          helm upgrade --install federated-pipeline ./helm/federated-pipeline \
            --namespace federated-pipeline \
            --create-namespace \
            --values ./helm/federated-pipeline/values-production.yaml \
            --set image.tag=${{ github.ref_name }} \
            --wait --timeout=600s

      - name: Run production smoke tests
        run: |
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aggregation-server -n federated-pipeline --timeout=300s
          curl -f https://federated-pipeline.company.com/health

      - name: Create GitHub release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ github.ref }}
          release_name: Release ${{ github.ref }}
          draft: false
          prerelease: false

  # Cleanup old images
  cleanup:
    needs: [deploy-production]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Delete old container images
        run: |
          # Keep only the last 10 images for each component
          for component in aggregation-server edge-coordinator sdr-client mobile-client metrics-collector; do
            echo "Cleaning up old images for $component"
            # This would typically use your registry's API to delete old images
            # Implementation depends on your container registry
          done